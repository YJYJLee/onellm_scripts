BATCH_SIZE=$1
HF_DATASETS_CACHE="/fsx-atom/shared/yj_cache" XDG_CACHE_HOME=/fsx-atom/shared/yj_cache TORCHINDUCTOR_CACHE_DIR=/fsx-atom/shared/yj_cache TRITON_CACHE_DIR=/fsx-atom/shared/yj_cache accelerate launch main.py --model meta-llama/CodeLlama-34b-hf --max_length_generation 10000 --tasks humaneval --temperature 0.2 --n_samples 1 --batch_size $BATCH_SIZE --allow_code_execution --precision fp16
HF_DATASETS_CACHE="/fsx-atom/shared/yj_cache" XDG_CACHE_HOME=/fsx-atom/shared/yj_cache TORCHINDUCTOR_CACHE_DIR=/fsx-atom/shared/yj_cache TRITON_CACHE_DIR=/fsx-atom/shared/yj_cache accelerate launch main.py --model meta-llama/CodeLlama-34b-hf --max_length_generation 10000 --tasks mbpp --temperature 0.1 --n_samples 1 --batch_size $BATCH_SIZE --allow_code_execution --precision fp16

HF_DATASETS_CACHE="/fsx-atom/shared/yj_cache" XDG_CACHE_HOME=/fsx-atom/shared/yj_cache TORCHINDUCTOR_CACHE_DIR=/fsx-atom/shared/yj_cache TRITON_CACHE_DIR=/fsx-atom/shared/yj_cache accelerate launch main.py --model meta-llama/CodeLlama-7b-hf --max_length_generation 10000 --tasks humaneval --temperature 0.2 --n_samples 1 --batch_size $BATCH_SIZE --allow_code_execution --precision fp16
HF_DATASETS_CACHE="/fsx-atom/shared/yj_cache" XDG_CACHE_HOME=/fsx-atom/shared/yj_cache TORCHINDUCTOR_CACHE_DIR=/fsx-atom/shared/yj_cache TRITON_CACHE_DIR=/fsx-atom/shared/yj_cache accelerate launch main.py --model meta-llama/CodeLlama-7b-hf --max_length_generation 10000 --tasks mbpp --temperature 0.1 --n_samples 1 --batch_size $BATCH_SIZE --allow_code_execution --precision fp16

